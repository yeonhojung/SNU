{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import date\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from progress.bar import ChargingBar as Bar\n",
    "import queue\n",
    "import math\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "from utils_IS import *\n",
    "from evaluate import *\n",
    "from S_DeepEns2.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "trainloader, testloader, n_train, n_test, p_data, num_classes = data_process('CIFAR10', '/home/ggong369/data/MBNN_ICML2023/datasets', seed, 100)\n",
    "\n",
    "task = 'classification'\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "\n",
    "mt=0\n",
    "\n",
    "model = M_ResNet18(num_classes).cuda()\n",
    "model.load_state_dict(torch.load('/home/ggong369/data/MBNN_ICML2023/experiments' + '/pretrain/' + 'CIFAR10' + '/221128/epoch100_lr0.001/seed_'+str(seed)+'_mt_'+str(mt)+'.pt', map_location='cuda:'+str(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, task, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    if task == 'regression':        \n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    elif task == 'classification':\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda().squeeze().long()\n",
    "            outputs = model(inputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "            \n",
    "def test(model, task, dataloader):\n",
    "    ERROR = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if task == 'regression':        \n",
    "            for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                outputs = model(inputs)\n",
    "                ERROR += ((targets - outputs)**2).sum()\n",
    "            return torch.sqrt(ERROR/len(dataloader.dataset))\n",
    "        \n",
    "        elif task == 'classification':\n",
    "            for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda().squeeze().long()\n",
    "                outputs = model(inputs)\n",
    "                ERROR += (torch.argmax(outputs,1) != targets).sum()    \n",
    "            return ERROR/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dist=[filter_ranks(model.conv1, model.bn1)]           \n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, M_BasicBlock):\n",
    "        original_dist = original_dist + layer.get_2norm()\n",
    "\n",
    "original_dist_stat = {}\n",
    "for k, stat in enumerate(original_dist):\n",
    "    a = stat.detach().cpu().numpy()\n",
    "    original_dist_stat[k] = {'mean': np.mean(a), 'std': np.std(a)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64., device='cuda:3')\n",
      "tensor(36., device='cuda:3')\n",
      "tensor(43., device='cuda:3')\n",
      "tensor(39., device='cuda:3')\n",
      "tensor(41., device='cuda:3')\n",
      "tensor(67., device='cuda:3')\n",
      "tensor(95., device='cuda:3')\n",
      "tensor(80., device='cuda:3')\n",
      "tensor(91., device='cuda:3')\n",
      "tensor(162., device='cuda:3')\n",
      "tensor(152., device='cuda:3')\n",
      "tensor(141., device='cuda:3')\n",
      "tensor(164., device='cuda:3')\n",
      "tensor(266., device='cuda:3')\n",
      "tensor(313., device='cuda:3')\n",
      "tensor(324., device='cuda:3')\n",
      "tensor(264., device='cuda:3')\n"
     ]
    }
   ],
   "source": [
    "perturbation = []\n",
    "\n",
    "for k in range(len(original_dist_stat)):\n",
    "    scale = np.exp(float(np.random.normal(0, 0.1))) / original_dist_stat[k]['std']\n",
    "    shift = float(np.random.normal(0, 0.1)- original_dist_stat[k]['mean']/ original_dist_stat[k]['std'])\n",
    "    perturbation.append((scale, shift))\n",
    "    \n",
    "model_tmp = copy.deepcopy(model)\n",
    "Masking_layers=[]\n",
    "for name, param in model_tmp.named_parameters():\n",
    "    if 'M_relu' in name:\n",
    "        Masking_layers.append(param)\n",
    "\n",
    "perturbed_dist = []\n",
    "for k in range(len(original_dist_stat)):\n",
    "    perturbed_dist.append(original_dist[k] * perturbation[k][0] + perturbation[k][1])\n",
    "\n",
    "cutoff = torch.quantile(torch.hstack(perturbed_dist), 1 - 0.6)\n",
    "\n",
    "for k in range(len(original_dist_stat)):\n",
    "    idx = torch.where(perturbed_dist[k] < cutoff)[0]\n",
    "    Masking_layers[k].data[idx] *= 0\n",
    "    if len(idx)==len(Masking_layers[k]):\n",
    "        idx = torch.argmax(perturbed_dist[k])\n",
    "        Masking_layers[k].data[idx] += 1\n",
    "                        \n",
    "for k in range(len(original_dist_stat)):\n",
    "    print(Masking_layers[k].data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8716, device='cuda:3')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_tmp, task, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'mean': 1.4768939, 'std': 2.3195174},\n",
       " 1: {'mean': 0.5173925, 'std': 0.4500004},\n",
       " 2: {'mean': 1.1012728, 'std': 0.7282056},\n",
       " 3: {'mean': 0.14502235, 'std': 0.059649426},\n",
       " 4: {'mean': 1.5524901, 'std': 0.74017715},\n",
       " 5: {'mean': 0.17625584, 'std': 0.07631205},\n",
       " 6: {'mean': 1.630589, 'std': 0.45739505},\n",
       " 7: {'mean': 0.24136806, 'std': 0.089614},\n",
       " 8: {'mean': 2.289945, 'std': 1.0323045},\n",
       " 9: {'mean': 0.19052489, 'std': 0.06343855},\n",
       " 10: {'mean': 2.0062778, 'std': 0.4994632},\n",
       " 11: {'mean': 0.51359177, 'std': 0.15950434},\n",
       " 12: {'mean': 4.8510866, 'std': 1.9786859},\n",
       " 13: {'mean': 0.4060076, 'std': 0.1599586},\n",
       " 14: {'mean': 1.8804797, 'std': 0.44032103},\n",
       " 15: {'mean': 0.06509709, 'std': 0.038639754},\n",
       " 16: {'mean': 0.018037803, 'std': 0.017243184}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dist_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
