{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_model import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(seed)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Data 다운로드 경로지정\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "#Data Process \n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]) \n",
    "\n",
    "transform_val = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "train_CIFAR10 = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "num_train = int(1.0 * len(train_CIFAR10) * 95 / 100)\n",
    "num_val = len(train_CIFAR10) - num_train\n",
    "train_CIFAR10, val_CIFAR10 = torch.utils.data.random_split(train_CIFAR10, [num_train, num_val])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_CIFAR10, batch_size=batch_size, shuffle=True, num_workers=2) #num_workers는 데이터 로드시 sub process 몇개 쓸거냐 \n",
    "val_loader = torch.utils.data.DataLoader(val_CIFAR10, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_CIFAR10, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR 100 : Data 다운로드 경로지정\n",
    "batch_size = 128\n",
    "\n",
    "#Data Process\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]) \n",
    "\n",
    "transform_val = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]) \n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]) \n",
    "\n",
    "train_CIFAR100 = torchvision.datasets.CIFAR100(root='../data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "test_CIFAR100 = torchvision.datasets.CIFAR100(root='../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "num_train = int(1.0 * len(train_CIFAR100) * 95 / 100)\n",
    "num_val = len(train_CIFAR100) - num_train\n",
    "train_CIFAR100, val_CIFAR100 = torch.utils.data.random_split(train_CIFAR100, [num_train, num_val])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_CIFAR100, batch_size=batch_size, shuffle=True, num_workers=2) #num_workers는 데이터 로드시 sub process 몇개 쓸거냐 \n",
    "val_loader = torch.utils.data.DataLoader(val_CIFAR100, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_CIFAR100, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_prune(model, pruning_ratio):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, M_BasicBlock):\n",
    "            # calculate cutoff value\n",
    "            nonzero_vals = layer.get_2norm()[0][layer.M_relu1.active != 0]\n",
    "            cutoff1 = torch.quantile(nonzero_vals, pruning_ratio)\n",
    "\n",
    "            # set inactive nodes to 0\n",
    "            layer.M_relu1.active.data[layer.get_2norm()[0] < cutoff1] *= 0\n",
    "            \n",
    "            # calculate cutoff value\n",
    "            nonzero_vals = layer.get_2norm()[1][layer.M_relu2.active != 0]\n",
    "            cutoff2 = torch.quantile(nonzero_vals, pruning_ratio)\n",
    "\n",
    "            # set inactive nodes to 0\n",
    "            layer.M_relu2.active.data[layer.get_2norm()[1] < cutoff2] *= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fine_tuning\n",
    "def fine_tuning(model, mode, EPOCHS, INITIAL_LR):\n",
    "    # total number of training epochs\n",
    "    CHECKPOINT_PATH = \"./save_seed100_CIFAR100\"\n",
    "\n",
    "    best_val_acc = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "    \n",
    "    remaining_node1 = sum([sum(layer.M_relu1.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "    remaining_node2 = sum([sum(layer.M_relu2.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "    print(f'최초 node의 갯수 : {remaining_node1, remaining_node2}')    \n",
    "\n",
    "    print(\"==> Training starts!\")\n",
    "    start = time.time()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)    \n",
    "    for i in range(EPOCHS):\n",
    "        if i % 40 == 0 :\n",
    "            print(f'{(i//40)+1}번 자르고 fine tuning을 시작합니다.')\n",
    "            node_prune(model, ratio)\n",
    "            \n",
    "            remaining_node1 = sum([sum(layer.M_relu1.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "            remaining_node2 = sum([sum(layer.M_relu2.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "\n",
    "            print(f'{(i//40)+1}번 pruning 이후 남은 node 는 : {(remaining_node1, remaining_node2)}')\n",
    "        \n",
    "        '''\n",
    "        train loop\n",
    "        '''            \n",
    "        model.train()\n",
    "        \n",
    "        # this help you compute the training accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "\n",
    "        train_loss = 0 # track training loss if you want\n",
    "\n",
    "        # Train the model for 1 epoch.\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).long() #inputs과 targets는 gpu로 계산\n",
    "\n",
    "            # compute the output and loss\n",
    "            y_preds = model(inputs)        \n",
    "            loss = criterion(y_preds,targets)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            y_preds_class = torch.argmax(y_preds, dim=1)\n",
    "            correct_examples += (targets == y_preds_class).sum().item()\n",
    "            total_examples += targets.size(0)\n",
    "\n",
    "        scheduler.step()    #스케쥴러 사용해보기\n",
    "            \n",
    "        avg_loss_tr = train_loss / len(train_loader) ###\n",
    "        avg_acc_tr = correct_examples / total_examples ### \n",
    "\n",
    "                                                      \n",
    "        '''\n",
    "        validation loop\n",
    "        '''\n",
    "                                                      \n",
    "        # switch to eval mode\n",
    "        model.eval()\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        val_loss = 0 # again, track the validation loss if you want\n",
    "        \n",
    "        # disable gradient during validation, which can save GPU memory\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).long()\n",
    "\n",
    "                # compute the output and loss\n",
    "                y_preds = model(inputs)        \n",
    "                loss = criterion(y_preds,targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # count the number of correctly predicted samples in the current batch\n",
    "                y_preds_class = torch.argmax(y_preds, dim=1)\n",
    "                correct_examples += (targets == y_preds_class).sum().item()\n",
    "                total_examples += targets.size(0)\n",
    "\n",
    "        avg_loss_val = val_loss / len(val_loader)\n",
    "        avg_acc_val = correct_examples / total_examples\n",
    "\n",
    "                                                      \n",
    "        # save the model checkpoint\n",
    "        if avg_acc_val > best_val_acc:\n",
    "            best_val_acc = avg_acc_val\n",
    "            if not os.path.exists(CHECKPOINT_PATH):\n",
    "                os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                     'epoch': i,\n",
    "                     'lr': current_learning_rate}\n",
    "            \n",
    "            torch.save(state, os.path.join(CHECKPOINT_PATH, '{}.pth'.format(mode)))        \n",
    "    \n",
    "        if i % 10 == 9 :  \n",
    "            end = time.time()\n",
    "            diff_time = round(end - start,2)\n",
    "            print(\"Epoch %d:\" %(i+1), f\"progress time is {diff_time} sec\")\n",
    "            print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss_val, avg_acc_val))\n",
    "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")                       \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###8. test_model\n",
    "def test_model(model):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            pred = model(inputs)\n",
    "            total_examples += inputs.shape[0]\n",
    "\n",
    "            out = softmax(pred)\n",
    "            out = torch.max(out, 1)\n",
    "\n",
    "            correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n",
    "\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Total examples is {}, correct examples is {}; Test accuracy: {}\".format(total_examples, correct_examples, avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 모델 지정 및 GPU 지정\n",
    "# device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = Wide_ResNet(28, 10, 0.3, 100).to(device)\n",
    "# check_prune = torch.load(\"../1.Wide_ResNet_model/saved_model/WR_28x10_cifar100.pth\")\n",
    "# model.load_state_dict(check_prune['state_dict'])\n",
    "# # test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "REG = 5e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "ratio = 1-0.4**0.1976\n",
    "\n",
    "basic = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n",
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2692.09 sec\n",
      "Validation loss: 0.0657, Validation accuracy: 0.9848\n",
      "Epoch 20: progress time is 5381.93 sec\n",
      "Validation loss: 0.0668, Validation accuracy: 0.9868\n",
      "Epoch 30: progress time is 8072.05 sec\n",
      "Validation loss: 0.0758, Validation accuracy: 0.9860\n",
      "Epoch 40: progress time is 10840.65 sec\n",
      "Validation loss: 0.0938, Validation accuracy: 0.9812\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 13732.45 sec\n",
      "Validation loss: 0.3505, Validation accuracy: 0.9060\n",
      "Epoch 60: progress time is 16532.09 sec\n",
      "Validation loss: 0.3138, Validation accuracy: 0.9176\n",
      "Epoch 70: progress time is 19606.39 sec\n",
      "Validation loss: 0.2348, Validation accuracy: 0.9376\n",
      "Epoch 80: progress time is 22294.7 sec\n",
      "Validation loss: 0.2381, Validation accuracy: 0.9412\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 24982.15 sec\n",
      "Validation loss: 0.3894, Validation accuracy: 0.9004\n",
      "Epoch 100: progress time is 27670.2 sec\n",
      "Validation loss: 0.3742, Validation accuracy: 0.9064\n",
      "Epoch 110: progress time is 30357.87 sec\n",
      "Validation loss: 0.3795, Validation accuracy: 0.9088\n",
      "Epoch 120: progress time is 33045.3 sec\n",
      "Validation loss: 0.3625, Validation accuracy: 0.9056\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 35730.33 sec\n",
      "Validation loss: 0.5539, Validation accuracy: 0.8580\n",
      "Epoch 140: progress time is 38415.76 sec\n",
      "Validation loss: 0.5662, Validation accuracy: 0.8576\n",
      "Epoch 150: progress time is 41100.04 sec\n",
      "Validation loss: 0.6175, Validation accuracy: 0.8504\n",
      "Epoch 160: progress time is 43785.56 sec\n",
      "Validation loss: 0.5300, Validation accuracy: 0.8676\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 46466.01 sec\n",
      "Validation loss: 0.8005, Validation accuracy: 0.8016\n",
      "Epoch 180: progress time is 49140.31 sec\n",
      "Validation loss: 0.8140, Validation accuracy: 0.8004\n",
      "Epoch 190: progress time is 51813.75 sec\n",
      "Validation loss: 0.7600, Validation accuracy: 0.8136\n",
      "Epoch 200: progress time is 54487.98 sec\n",
      "Validation loss: 0.7102, Validation accuracy: 0.8200\n",
      "==> Optimization finished! Best validation accuracy: 0.9900\n",
      "Total examples is 10000, correct examples is 7915; Test accuracy: 0.7915\n",
      "| Wide-Resnet 28x10\n",
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2694.24 sec\n",
      "Validation loss: 0.7076, Validation accuracy: 0.7952\n",
      "Epoch 20: progress time is 5383.94 sec\n",
      "Validation loss: 0.8322, Validation accuracy: 0.7648\n",
      "Epoch 30: progress time is 8073.43 sec\n",
      "Validation loss: 0.9039, Validation accuracy: 0.7596\n",
      "Epoch 40: progress time is 10762.55 sec\n",
      "Validation loss: 0.9266, Validation accuracy: 0.7544\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 13450.94 sec\n",
      "Validation loss: 1.0682, Validation accuracy: 0.7264\n",
      "Epoch 60: progress time is 16139.46 sec\n",
      "Validation loss: 1.0992, Validation accuracy: 0.7220\n",
      "Epoch 70: progress time is 18833.51 sec\n",
      "Validation loss: 0.6894, Validation accuracy: 0.8252\n",
      "Epoch 80: progress time is 21523.82 sec\n",
      "Validation loss: 0.6631, Validation accuracy: 0.8260\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 24212.13 sec\n",
      "Validation loss: 0.7707, Validation accuracy: 0.8044\n",
      "Epoch 100: progress time is 26899.37 sec\n",
      "Validation loss: 0.7799, Validation accuracy: 0.8096\n",
      "Epoch 110: progress time is 29586.23 sec\n",
      "Validation loss: 0.7723, Validation accuracy: 0.8128\n",
      "Epoch 120: progress time is 32272.03 sec\n",
      "Validation loss: 0.8110, Validation accuracy: 0.7988\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 34952.87 sec\n",
      "Validation loss: 0.8884, Validation accuracy: 0.7772\n",
      "Epoch 140: progress time is 37629.79 sec\n",
      "Validation loss: 0.8719, Validation accuracy: 0.7864\n",
      "Epoch 150: progress time is 40306.92 sec\n",
      "Validation loss: 0.8605, Validation accuracy: 0.7972\n",
      "Epoch 160: progress time is 42983.94 sec\n",
      "Validation loss: 0.8748, Validation accuracy: 0.7852\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 45657.58 sec\n",
      "Validation loss: 0.9724, Validation accuracy: 0.7624\n",
      "Epoch 180: progress time is 48331.68 sec\n",
      "Validation loss: 0.9801, Validation accuracy: 0.7540\n",
      "Epoch 190: progress time is 51006.66 sec\n",
      "Validation loss: 1.0207, Validation accuracy: 0.7556\n",
      "Epoch 200: progress time is 53681.31 sec\n",
      "Validation loss: 0.9896, Validation accuracy: 0.7592\n",
      "==> Optimization finished! Best validation accuracy: 0.8312\n",
      "Total examples is 10000, correct examples is 7827; Test accuracy: 0.7827\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.004, 0.02] :\n",
    "    model = Wide_ResNet(28, basic, 0.3, 100).to(device)        \n",
    "    ## train\n",
    "    checkpoint = torch.load(f\"../1.Wide_ResNet_model/saved_model/WR_28x{basic}_cifar100.pth\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    fine_tuning(model, mode=f\"28x{basic}_0.6_multistepLR_lr{lr}\", EPOCHS=200, INITIAL_LR=lr)\n",
    "\n",
    "    ## test\n",
    "    checkpoint_path = f\"./save_seed{seed}_CIFAR100/28x{basic}_0.6_multistepLR_lr{lr}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    test_model(model)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fine_tuning\n",
    "def fine_tuning(model, mode, EPOCHS, INITIAL_LR):\n",
    "    # total number of training epochs\n",
    "    CHECKPOINT_PATH = \"./save_seed100_CIFAR100\"\n",
    "\n",
    "    best_val_acc = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "    \n",
    "    remaining_node1 = sum([sum(layer.M_relu1.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "    remaining_node2 = sum([sum(layer.M_relu2.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "    print(f'최초 node의 갯수 : {remaining_node1, remaining_node2}')    \n",
    "\n",
    "    print(\"==> Training starts!\")\n",
    "    start = time.time()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)    \n",
    "    for i in range(EPOCHS):\n",
    "        if i % 40 == 0 :\n",
    "            print(f'{(i//40)+1}번 자르고 fine tuning을 시작합니다.')\n",
    "            node_prune(model, ratio)\n",
    "            \n",
    "            remaining_node1 = sum([sum(layer.M_relu1.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "            remaining_node2 = sum([sum(layer.M_relu2.active) for layer in model.modules() if isinstance(layer, M_BasicBlock)])\n",
    "\n",
    "            print(f'{(i//40)+1}번 pruning 이후 남은 node 는 : {(remaining_node1, remaining_node2)}')\n",
    "        \n",
    "        '''\n",
    "        train loop\n",
    "        '''            \n",
    "        model.train()\n",
    "        \n",
    "        # this help you compute the training accuracy\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "\n",
    "        train_loss = 0 # track training loss if you want\n",
    "\n",
    "        # Train the model for 1 epoch.\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).long() #inputs과 targets는 gpu로 계산\n",
    "\n",
    "            # compute the output and loss\n",
    "            y_preds = model(inputs)        \n",
    "            loss = criterion(y_preds,targets)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            y_preds_class = torch.argmax(y_preds, dim=1)\n",
    "            correct_examples += (targets == y_preds_class).sum().item()\n",
    "            total_examples += targets.size(0)\n",
    "\n",
    "        scheduler.step()    #스케쥴러 사용해보기\n",
    "            \n",
    "        avg_loss_tr = train_loss / len(train_loader) ###\n",
    "        avg_acc_tr = correct_examples / total_examples ### \n",
    "\n",
    "                                                      \n",
    "        '''\n",
    "        validation loop\n",
    "        '''\n",
    "                                                      \n",
    "        # switch to eval mode\n",
    "        model.eval()\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        val_loss = 0 # again, track the validation loss if you want\n",
    "        \n",
    "        # disable gradient during validation, which can save GPU memory\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).long()\n",
    "\n",
    "                # compute the output and loss\n",
    "                y_preds = model(inputs)        \n",
    "                loss = criterion(y_preds,targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # count the number of correctly predicted samples in the current batch\n",
    "                y_preds_class = torch.argmax(y_preds, dim=1)\n",
    "                correct_examples += (targets == y_preds_class).sum().item()\n",
    "                total_examples += targets.size(0)\n",
    "\n",
    "        avg_loss_val = val_loss / len(val_loader)\n",
    "        avg_acc_val = correct_examples / total_examples\n",
    "\n",
    "                                                      \n",
    "        # save the model checkpoint\n",
    "        if avg_acc_val > best_val_acc:\n",
    "            best_val_acc = avg_acc_val\n",
    "            if not os.path.exists(CHECKPOINT_PATH):\n",
    "                os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                     'epoch': i,\n",
    "                     'lr': current_learning_rate}\n",
    "            \n",
    "            torch.save(state, os.path.join(CHECKPOINT_PATH, '{}.pth'.format(mode)))        \n",
    "    \n",
    "        if i % 10 == 9 :  \n",
    "            end = time.time()\n",
    "            diff_time = round(end - start,2)\n",
    "            print(\"Epoch %d:\" %(i+1), f\"progress time is {diff_time} sec\")\n",
    "            print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss_val, avg_acc_val))\n",
    "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")                       \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n",
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2698.63 sec\n",
      "Validation loss: 0.0576, Validation accuracy: 0.9884\n",
      "Epoch 20: progress time is 5394.83 sec\n",
      "Validation loss: 0.0648, Validation accuracy: 0.9860\n",
      "Epoch 30: progress time is 8089.36 sec\n",
      "Validation loss: 0.0876, Validation accuracy: 0.9812\n",
      "Epoch 40: progress time is 10784.91 sec\n",
      "Validation loss: 0.0842, Validation accuracy: 0.9848\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 13474.71 sec\n",
      "Validation loss: 0.1820, Validation accuracy: 0.9576\n",
      "Epoch 60: progress time is 16164.83 sec\n",
      "Validation loss: 0.1647, Validation accuracy: 0.9652\n",
      "Epoch 70: progress time is 18854.57 sec\n",
      "Validation loss: 0.1596, Validation accuracy: 0.9668\n",
      "Epoch 80: progress time is 21544.07 sec\n",
      "Validation loss: 0.1647, Validation accuracy: 0.9640\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 24299.97 sec\n",
      "Validation loss: 0.3526, Validation accuracy: 0.9196\n",
      "Epoch 100: progress time is 26990.26 sec\n",
      "Validation loss: 0.3087, Validation accuracy: 0.9328\n",
      "Epoch 110: progress time is 29681.5 sec\n",
      "Validation loss: 0.2925, Validation accuracy: 0.9408\n",
      "Epoch 120: progress time is 32371.27 sec\n",
      "Validation loss: 0.3173, Validation accuracy: 0.9232\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 35060.27 sec\n",
      "Validation loss: 0.6256, Validation accuracy: 0.8384\n",
      "Epoch 140: progress time is 37749.33 sec\n",
      "Validation loss: 0.8328, Validation accuracy: 0.7836\n",
      "Epoch 150: progress time is 40438.91 sec\n",
      "Validation loss: 0.7869, Validation accuracy: 0.7964\n",
      "Epoch 160: progress time is 43126.71 sec\n",
      "Validation loss: 0.9003, Validation accuracy: 0.7712\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 45804.55 sec\n",
      "Validation loss: 1.1134, Validation accuracy: 0.7208\n",
      "Epoch 180: progress time is 48480.63 sec\n",
      "Validation loss: 1.0806, Validation accuracy: 0.7396\n",
      "Epoch 190: progress time is 51157.74 sec\n",
      "Validation loss: 1.0542, Validation accuracy: 0.7448\n",
      "Epoch 200: progress time is 53834.94 sec\n",
      "Validation loss: 1.0626, Validation accuracy: 0.7432\n",
      "==> Optimization finished! Best validation accuracy: 0.9884\n",
      "Total examples is 10000, correct examples is 7884; Test accuracy: 0.7884\n",
      "| Wide-Resnet 28x10\n",
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2695.19 sec\n",
      "Validation loss: 0.7301, Validation accuracy: 0.8012\n",
      "Epoch 20: progress time is 5384.62 sec\n",
      "Validation loss: 0.7904, Validation accuracy: 0.7892\n",
      "Epoch 30: progress time is 8073.49 sec\n",
      "Validation loss: 0.7295, Validation accuracy: 0.8060\n",
      "Epoch 40: progress time is 10859.81 sec\n",
      "Validation loss: 0.7596, Validation accuracy: 0.7988\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 13980.87 sec\n",
      "Validation loss: 0.7338, Validation accuracy: 0.8084\n",
      "Epoch 60: progress time is 17251.9 sec\n",
      "Validation loss: 0.6410, Validation accuracy: 0.8344\n",
      "Epoch 70: progress time is 20715.82 sec\n",
      "Validation loss: 0.6078, Validation accuracy: 0.8400\n",
      "Epoch 80: progress time is 23456.9 sec\n",
      "Validation loss: 0.6001, Validation accuracy: 0.8484\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 26140.57 sec\n",
      "Validation loss: 0.7385, Validation accuracy: 0.8136\n",
      "Epoch 100: progress time is 28824.57 sec\n",
      "Validation loss: 0.6899, Validation accuracy: 0.8268\n",
      "Epoch 110: progress time is 31509.67 sec\n",
      "Validation loss: 0.7455, Validation accuracy: 0.8124\n",
      "Epoch 120: progress time is 34195.4 sec\n",
      "Validation loss: 0.7198, Validation accuracy: 0.8220\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 36878.28 sec\n",
      "Validation loss: 1.1035, Validation accuracy: 0.7132\n",
      "Epoch 140: progress time is 39560.19 sec\n",
      "Validation loss: 1.2822, Validation accuracy: 0.6772\n",
      "Epoch 150: progress time is 42241.0 sec\n",
      "Validation loss: 1.2495, Validation accuracy: 0.6924\n",
      "Epoch 160: progress time is 44922.54 sec\n",
      "Validation loss: 1.1999, Validation accuracy: 0.7048\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 47602.12 sec\n",
      "Validation loss: 1.4149, Validation accuracy: 0.6620\n",
      "Epoch 180: progress time is 50279.16 sec\n",
      "Validation loss: 1.4214, Validation accuracy: 0.6544\n",
      "Epoch 190: progress time is 52956.96 sec\n",
      "Validation loss: 1.5064, Validation accuracy: 0.6528\n",
      "Epoch 200: progress time is 55635.59 sec\n",
      "Validation loss: 1.4353, Validation accuracy: 0.6536\n",
      "==> Optimization finished! Best validation accuracy: 0.8484\n",
      "Total examples is 10000, correct examples is 7920; Test accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.004, 0.02]:\n",
    "    model = Wide_ResNet(28, basic, 0.3, 100).to(device)        \n",
    "    ## train\n",
    "    checkpoint = torch.load(f\"../1.Wide_ResNet_model/saved_model/WR_28x{basic}_cifar100.pth\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    fine_tuning(model, mode=f\"28x{basic}_0.6_multistepLR_lr{lr}\", EPOCHS=200, INITIAL_LR=lr)\n",
    "\n",
    "    ## test\n",
    "    checkpoint_path = f\"./save_seed{seed}_CIFAR100/28x{basic}_0.6_multistepLR_lr{lr}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    test_model(model)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n",
      "Total examples is 10000, correct examples is 7915; Test accuracy: 0.7915\n",
      "| Wide-Resnet 28x10\n",
      "Total examples is 10000, correct examples is 7827; Test accuracy: 0.7827\n",
      "| Wide-Resnet 28x10\n",
      "Total examples is 10000, correct examples is 7884; Test accuracy: 0.7884\n",
      "| Wide-Resnet 28x10\n",
      "Total examples is 10000, correct examples is 7920; Test accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.004, 0.02]:\n",
    "    model = Wide_ResNet(28, basic, 0.3, 100).to(device)        \n",
    "    ## test\n",
    "    checkpoint_path = f\"./save_seed{seed}_CIFAR100/28x{basic}_0.6_multistepLR_lr{lr}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    test_model(model)   \n",
    "for lr in [0.004, 0.02]:\n",
    "    model = Wide_ResNet(28, basic, 0.3, 100).to(device)        \n",
    "    ## test\n",
    "    checkpoint_path = f\"./save_seed{seed}_CIFAR100/28x{basic}_0.6_cosine_lr{lr}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    test_model(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2529.39 sec\n",
      "Validation loss: 0.2105, Validation accuracy: 0.9340\n",
      "Epoch 20: progress time is 5039.73 sec\n",
      "Validation loss: 0.2226, Validation accuracy: 0.9332\n",
      "Epoch 30: progress time is 7556.91 sec\n",
      "Validation loss: 0.2452, Validation accuracy: 0.9288\n",
      "Epoch 40: progress time is 10068.8 sec\n",
      "Validation loss: 0.2201, Validation accuracy: 0.9400\n",
      "41번 자르고 fine tuning을 시작합니다.\n",
      "41번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 12588.52 sec\n",
      "Validation loss: 0.2263, Validation accuracy: 0.9372\n",
      "Epoch 60: progress time is 15117.7 sec\n",
      "Validation loss: 0.1511, Validation accuracy: 0.9580\n",
      "Epoch 70: progress time is 17616.53 sec\n",
      "Validation loss: 0.1407, Validation accuracy: 0.9600\n",
      "Epoch 80: progress time is 20097.79 sec\n",
      "Validation loss: 0.1367, Validation accuracy: 0.9628\n",
      "81번 자르고 fine tuning을 시작합니다.\n",
      "81번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 22572.24 sec\n",
      "Validation loss: 0.1538, Validation accuracy: 0.9556\n",
      "Epoch 100: progress time is 25047.19 sec\n",
      "Validation loss: 0.1393, Validation accuracy: 0.9580\n",
      "Epoch 110: progress time is 27524.69 sec\n",
      "Validation loss: 0.1564, Validation accuracy: 0.9600\n",
      "Epoch 120: progress time is 30003.56 sec\n",
      "Validation loss: 0.1594, Validation accuracy: 0.9576\n",
      "121번 자르고 fine tuning을 시작합니다.\n",
      "121번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 32473.61 sec\n",
      "Validation loss: 0.2233, Validation accuracy: 0.9280\n",
      "Epoch 140: progress time is 34940.5 sec\n",
      "Validation loss: 0.2517, Validation accuracy: 0.9240\n",
      "Epoch 150: progress time is 37407.01 sec\n",
      "Validation loss: 0.2431, Validation accuracy: 0.9352\n",
      "Epoch 160: progress time is 39870.67 sec\n",
      "Validation loss: 0.2547, Validation accuracy: 0.9264\n",
      "161번 자르고 fine tuning을 시작합니다.\n",
      "161번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 42321.55 sec\n",
      "Validation loss: 0.3540, Validation accuracy: 0.8976\n",
      "Epoch 180: progress time is 44776.08 sec\n",
      "Validation loss: 0.2676, Validation accuracy: 0.9160\n",
      "Epoch 190: progress time is 47232.04 sec\n",
      "Validation loss: 0.4032, Validation accuracy: 0.8820\n",
      "Epoch 200: progress time is 49688.04 sec\n",
      "Validation loss: 0.2711, Validation accuracy: 0.9172\n",
      "==> Optimization finished! Best validation accuracy: 0.9648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##scheduler 실행 : cosineannealingLR\n",
    "fine_tuning(model, mode = '28x10_CIFAR10_scheduler_cosine_lr0.1*0.2', EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:0'), tensor(4480., device='cuda:0'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:0'), tensor(3736., device='cuda:0'))\n",
      "Epoch 10: progress time is 2700.71 sec\n",
      "Validation loss: 0.1402, Validation accuracy: 0.9612\n",
      "Epoch 20: progress time is 5394.24 sec\n",
      "Validation loss: 0.1591, Validation accuracy: 0.9548\n",
      "Epoch 30: progress time is 8090.0 sec\n",
      "Validation loss: 0.2017, Validation accuracy: 0.9412\n",
      "Epoch 40: progress time is 11040.36 sec\n",
      "Validation loss: 0.1533, Validation accuracy: 0.9560\n",
      "41번 자르고 fine tuning을 시작합니다.\n",
      "41번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:0'), tensor(3112., device='cuda:0'))\n",
      "Epoch 50: progress time is 13989.13 sec\n",
      "Validation loss: 0.2245, Validation accuracy: 0.9368\n",
      "Epoch 60: progress time is 17695.93 sec\n",
      "Validation loss: 0.1893, Validation accuracy: 0.9456\n",
      "Epoch 70: progress time is 20388.98 sec\n",
      "Validation loss: 0.1389, Validation accuracy: 0.9580\n",
      "Epoch 80: progress time is 23080.64 sec\n",
      "Validation loss: 0.1471, Validation accuracy: 0.9592\n",
      "81번 자르고 fine tuning을 시작합니다.\n",
      "81번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:0'), tensor(2592., device='cuda:0'))\n",
      "Epoch 90: progress time is 25771.87 sec\n",
      "Validation loss: 0.1624, Validation accuracy: 0.9552\n",
      "Epoch 100: progress time is 28460.39 sec\n",
      "Validation loss: 0.1494, Validation accuracy: 0.9592\n",
      "Epoch 110: progress time is 31151.36 sec\n",
      "Validation loss: 0.1825, Validation accuracy: 0.9536\n",
      "Epoch 120: progress time is 33842.1 sec\n",
      "Validation loss: 0.1782, Validation accuracy: 0.9524\n",
      "121번 자르고 fine tuning을 시작합니다.\n",
      "121번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:0'), tensor(2156., device='cuda:0'))\n",
      "Epoch 130: progress time is 36537.12 sec\n",
      "Validation loss: 0.2005, Validation accuracy: 0.9472\n",
      "Epoch 140: progress time is 39227.84 sec\n",
      "Validation loss: 0.1713, Validation accuracy: 0.9552\n",
      "Epoch 150: progress time is 41919.94 sec\n",
      "Validation loss: 0.1567, Validation accuracy: 0.9596\n",
      "Epoch 160: progress time is 44609.3 sec\n",
      "Validation loss: 0.1687, Validation accuracy: 0.9552\n",
      "161번 자르고 fine tuning을 시작합니다.\n",
      "161번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:0'), tensor(1792., device='cuda:0'))\n",
      "Epoch 170: progress time is 47301.2 sec\n",
      "Validation loss: 0.2379, Validation accuracy: 0.9312\n",
      "Epoch 180: progress time is 49997.44 sec\n",
      "Validation loss: 0.2134, Validation accuracy: 0.9432\n",
      "Epoch 190: progress time is 52681.59 sec\n",
      "Validation loss: 0.1997, Validation accuracy: 0.9444\n",
      "Epoch 200: progress time is 55371.29 sec\n",
      "Validation loss: 0.2109, Validation accuracy: 0.9448\n",
      "==> Optimization finished! Best validation accuracy: 0.9652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##scheduler 실행 : cosineannealingLR\n",
    "fine_tuning(model, mode = '28x10_0.6_CIFAR10_scheduler_mult_lr0.1*0.2*0.2', EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2523.44 sec\n",
      "Validation loss: 0.0625, Validation accuracy: 0.9876\n",
      "Epoch 20: progress time is 5041.51 sec\n",
      "Validation loss: 0.0617, Validation accuracy: 0.9884\n",
      "Epoch 30: progress time is 7557.95 sec\n",
      "Validation loss: 0.0771, Validation accuracy: 0.9832\n",
      "Epoch 40: progress time is 10073.43 sec\n",
      "Validation loss: 0.0901, Validation accuracy: 0.9832\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 12593.96 sec\n",
      "Validation loss: 0.3467, Validation accuracy: 0.9004\n",
      "Epoch 60: progress time is 15124.31 sec\n",
      "Validation loss: 0.3305, Validation accuracy: 0.9104\n",
      "Epoch 70: progress time is 17651.85 sec\n",
      "Validation loss: 0.2623, Validation accuracy: 0.9352\n",
      "Epoch 80: progress time is 20182.01 sec\n",
      "Validation loss: 0.2420, Validation accuracy: 0.9388\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 22694.25 sec\n",
      "Validation loss: 0.3713, Validation accuracy: 0.9008\n",
      "Epoch 100: progress time is 25211.12 sec\n",
      "Validation loss: 0.3742, Validation accuracy: 0.9008\n",
      "Epoch 110: progress time is 27725.11 sec\n",
      "Validation loss: 0.3650, Validation accuracy: 0.9064\n",
      "Epoch 120: progress time is 30240.73 sec\n",
      "Validation loss: 0.3703, Validation accuracy: 0.9004\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 32747.42 sec\n",
      "Validation loss: 0.5671, Validation accuracy: 0.8552\n",
      "Epoch 140: progress time is 35251.1 sec\n",
      "Validation loss: 0.5399, Validation accuracy: 0.8592\n",
      "Epoch 150: progress time is 37752.46 sec\n",
      "Validation loss: 0.5010, Validation accuracy: 0.8764\n",
      "Epoch 160: progress time is 40255.33 sec\n",
      "Validation loss: 0.5134, Validation accuracy: 0.8656\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 42743.79 sec\n",
      "Validation loss: 0.7958, Validation accuracy: 0.7984\n",
      "Epoch 180: progress time is 45233.36 sec\n",
      "Validation loss: 0.7843, Validation accuracy: 0.7980\n",
      "Epoch 190: progress time is 47723.39 sec\n",
      "Validation loss: 0.8129, Validation accuracy: 0.7892\n",
      "Epoch 200: progress time is 50212.01 sec\n",
      "Validation loss: 0.7709, Validation accuracy: 0.8184\n",
      "==> Optimization finished! Best validation accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##scheduler 실행 : cosineannealingLR\n",
    "fine_tuning(model, mode = mode, EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:1'), tensor(4480., device='cuda:1'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:1'), tensor(3736., device='cuda:1'))\n",
      "Epoch 10: progress time is 2522.41 sec\n",
      "Validation loss: 0.7077, Validation accuracy: 0.8040\n",
      "Epoch 20: progress time is 5039.43 sec\n",
      "Validation loss: 0.7873, Validation accuracy: 0.7928\n",
      "Epoch 30: progress time is 7550.57 sec\n",
      "Validation loss: 0.8077, Validation accuracy: 0.7788\n",
      "Epoch 40: progress time is 10068.45 sec\n",
      "Validation loss: 0.8540, Validation accuracy: 0.7704\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:1'), tensor(3112., device='cuda:1'))\n",
      "Epoch 50: progress time is 12592.23 sec\n",
      "Validation loss: 0.9083, Validation accuracy: 0.7564\n",
      "Epoch 60: progress time is 15121.25 sec\n",
      "Validation loss: 1.0312, Validation accuracy: 0.7432\n",
      "Epoch 70: progress time is 17649.12 sec\n",
      "Validation loss: 0.6681, Validation accuracy: 0.8232\n",
      "Epoch 80: progress time is 20142.73 sec\n",
      "Validation loss: 0.6351, Validation accuracy: 0.8316\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:1'), tensor(2592., device='cuda:1'))\n",
      "Epoch 90: progress time is 22620.28 sec\n",
      "Validation loss: 0.7212, Validation accuracy: 0.8124\n",
      "Epoch 100: progress time is 25104.38 sec\n",
      "Validation loss: 0.7467, Validation accuracy: 0.8176\n",
      "Epoch 110: progress time is 27578.84 sec\n",
      "Validation loss: 0.7203, Validation accuracy: 0.8212\n",
      "Epoch 120: progress time is 30055.71 sec\n",
      "Validation loss: 0.7676, Validation accuracy: 0.8128\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:1'), tensor(2156., device='cuda:1'))\n",
      "Epoch 130: progress time is 32517.5 sec\n",
      "Validation loss: 0.8291, Validation accuracy: 0.7964\n",
      "Epoch 140: progress time is 34983.57 sec\n",
      "Validation loss: 0.8197, Validation accuracy: 0.8008\n",
      "Epoch 150: progress time is 37446.84 sec\n",
      "Validation loss: 0.8195, Validation accuracy: 0.7976\n",
      "Epoch 160: progress time is 39914.29 sec\n",
      "Validation loss: 0.8483, Validation accuracy: 0.7968\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:1'), tensor(1792., device='cuda:1'))\n",
      "Epoch 170: progress time is 42366.68 sec\n",
      "Validation loss: 1.0199, Validation accuracy: 0.7520\n",
      "Epoch 180: progress time is 44819.85 sec\n",
      "Validation loss: 0.9791, Validation accuracy: 0.7684\n",
      "Epoch 190: progress time is 47271.01 sec\n",
      "Validation loss: 1.0034, Validation accuracy: 0.7668\n",
      "Epoch 200: progress time is 49728.84 sec\n",
      "Validation loss: 0.9745, Validation accuracy: 0.7612\n",
      "==> Optimization finished! Best validation accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##scheduler 실행 : cosineannealingLR\n",
    "fine_tuning(model, mode = mode, EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seed 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:0'), tensor(4480., device='cuda:0'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:0'), tensor(3736., device='cuda:0'))\n",
      "Epoch 10: progress time is 2717.24 sec\n",
      "Validation loss: 0.0118, Validation accuracy: 0.9964\n",
      "Epoch 20: progress time is 5427.68 sec\n",
      "Validation loss: 0.0161, Validation accuracy: 0.9960\n",
      "Epoch 30: progress time is 8138.01 sec\n",
      "Validation loss: 0.0149, Validation accuracy: 0.9968\n",
      "Epoch 40: progress time is 10849.08 sec\n",
      "Validation loss: 0.0280, Validation accuracy: 0.9916\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:0'), tensor(3112., device='cuda:0'))\n",
      "Epoch 50: progress time is 13550.98 sec\n",
      "Validation loss: 0.1227, Validation accuracy: 0.9596\n",
      "Epoch 60: progress time is 16253.19 sec\n",
      "Validation loss: 0.0752, Validation accuracy: 0.9752\n",
      "Epoch 70: progress time is 18955.02 sec\n",
      "Validation loss: 0.0265, Validation accuracy: 0.9908\n",
      "Epoch 80: progress time is 21654.97 sec\n",
      "Validation loss: 0.0346, Validation accuracy: 0.9872\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:0'), tensor(2592., device='cuda:0'))\n",
      "Epoch 90: progress time is 24348.31 sec\n",
      "Validation loss: 0.0467, Validation accuracy: 0.9852\n",
      "Epoch 100: progress time is 27041.28 sec\n",
      "Validation loss: 0.0497, Validation accuracy: 0.9848\n",
      "Epoch 110: progress time is 29742.57 sec\n",
      "Validation loss: 0.0543, Validation accuracy: 0.9824\n",
      "Epoch 120: progress time is 32438.23 sec\n",
      "Validation loss: 0.0483, Validation accuracy: 0.9848\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:0'), tensor(2156., device='cuda:0'))\n",
      "Epoch 130: progress time is 35135.78 sec\n",
      "Validation loss: 0.0807, Validation accuracy: 0.9716\n",
      "Epoch 140: progress time is 37832.52 sec\n",
      "Validation loss: 0.0608, Validation accuracy: 0.9788\n",
      "Epoch 150: progress time is 40526.37 sec\n",
      "Validation loss: 0.0718, Validation accuracy: 0.9784\n",
      "Epoch 160: progress time is 43221.44 sec\n",
      "Validation loss: 0.0654, Validation accuracy: 0.9808\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:0'), tensor(1792., device='cuda:0'))\n",
      "Epoch 170: progress time is 45918.87 sec\n",
      "Validation loss: 0.1210, Validation accuracy: 0.9640\n",
      "Epoch 180: progress time is 48614.58 sec\n",
      "Validation loss: 0.1066, Validation accuracy: 0.9720\n",
      "Epoch 190: progress time is 51310.73 sec\n",
      "Validation loss: 0.0896, Validation accuracy: 0.9728\n",
      "Epoch 200: progress time is 54002.83 sec\n",
      "Validation loss: 0.0854, Validation accuracy: 0.9740\n",
      "==> Optimization finished! Best validation accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##scheduler 실행 : multistepLR , lr 0.1*0.2*0.2\n",
    "fine_tuning(model, mode = mode, EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:2'), tensor(4480., device='cuda:2'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:2'), tensor(3736., device='cuda:2'))\n",
      "Epoch 10: progress time is 3364.86 sec\n",
      "Validation loss: 0.1541, Validation accuracy: 0.9456\n",
      "Epoch 20: progress time is 7386.3 sec\n",
      "Validation loss: 0.1844, Validation accuracy: 0.9440\n",
      "Epoch 30: progress time is 10234.53 sec\n",
      "Validation loss: 0.1951, Validation accuracy: 0.9408\n",
      "Epoch 40: progress time is 13181.36 sec\n",
      "Validation loss: 0.1797, Validation accuracy: 0.9488\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:2'), tensor(3112., device='cuda:2'))\n",
      "Epoch 50: progress time is 16816.63 sec\n",
      "Validation loss: 0.1909, Validation accuracy: 0.9372\n",
      "Epoch 60: progress time is 20430.65 sec\n",
      "Validation loss: 0.2084, Validation accuracy: 0.9372\n",
      "Epoch 70: progress time is 23280.47 sec\n",
      "Validation loss: 0.1076, Validation accuracy: 0.9680\n",
      "Epoch 80: progress time is 26130.12 sec\n",
      "Validation loss: 0.1103, Validation accuracy: 0.9672\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:2'), tensor(2592., device='cuda:2'))\n",
      "Epoch 90: progress time is 28979.05 sec\n",
      "Validation loss: 0.1369, Validation accuracy: 0.9604\n",
      "Epoch 100: progress time is 31827.77 sec\n",
      "Validation loss: 0.1215, Validation accuracy: 0.9676\n",
      "Epoch 110: progress time is 34676.24 sec\n",
      "Validation loss: 0.1202, Validation accuracy: 0.9640\n",
      "Epoch 120: progress time is 37524.88 sec\n",
      "Validation loss: 0.1518, Validation accuracy: 0.9596\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:2'), tensor(2156., device='cuda:2'))\n",
      "Epoch 130: progress time is 40373.5 sec\n",
      "Validation loss: 0.1437, Validation accuracy: 0.9588\n",
      "Epoch 140: progress time is 43222.79 sec\n",
      "Validation loss: 0.1316, Validation accuracy: 0.9640\n",
      "Epoch 150: progress time is 46072.01 sec\n",
      "Validation loss: 0.1348, Validation accuracy: 0.9636\n",
      "Epoch 160: progress time is 48921.24 sec\n",
      "Validation loss: 0.1373, Validation accuracy: 0.9612\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:2'), tensor(1792., device='cuda:2'))\n",
      "Epoch 170: progress time is 51771.13 sec\n",
      "Validation loss: 0.1739, Validation accuracy: 0.9500\n",
      "Epoch 180: progress time is 54620.24 sec\n",
      "Validation loss: 0.1742, Validation accuracy: 0.9536\n",
      "Epoch 190: progress time is 57460.14 sec\n",
      "Validation loss: 0.1785, Validation accuracy: 0.9496\n",
      "Epoch 200: progress time is 60302.38 sec\n",
      "Validation loss: 0.1490, Validation accuracy: 0.9580\n",
      "==> Optimization finished! Best validation accuracy: 0.9708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##scheduler 실행 : multistepLR , lr 0.1*0.2\n",
    "fine_tuning(model, mode = mode, EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:0'), tensor(4480., device='cuda:0'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:0'), tensor(3736., device='cuda:0'))\n",
      "Epoch 10: progress time is 3003.98 sec\n",
      "Validation loss: 0.0912, Validation accuracy: 0.9820\n",
      "Epoch 20: progress time is 6504.1 sec\n",
      "Validation loss: 0.0811, Validation accuracy: 0.9848\n",
      "Epoch 30: progress time is 9590.9 sec\n",
      "Validation loss: 0.0809, Validation accuracy: 0.9860\n",
      "Epoch 40: progress time is 12323.84 sec\n",
      "Validation loss: 0.1062, Validation accuracy: 0.9772\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:0'), tensor(3112., device='cuda:0'))\n",
      "Epoch 50: progress time is 15056.59 sec\n",
      "Validation loss: 0.3893, Validation accuracy: 0.8988\n",
      "Epoch 60: progress time is 17796.11 sec\n",
      "Validation loss: 0.3513, Validation accuracy: 0.9072\n",
      "Epoch 70: progress time is 20537.48 sec\n",
      "Validation loss: 0.2733, Validation accuracy: 0.9256\n",
      "Epoch 80: progress time is 23273.0 sec\n",
      "Validation loss: 0.2713, Validation accuracy: 0.9300\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:0'), tensor(2592., device='cuda:0'))\n",
      "Epoch 90: progress time is 26021.75 sec\n",
      "Validation loss: 0.4043, Validation accuracy: 0.9016\n",
      "Epoch 100: progress time is 28774.45 sec\n",
      "Validation loss: 0.3965, Validation accuracy: 0.9008\n",
      "Epoch 110: progress time is 31529.49 sec\n",
      "Validation loss: 0.4154, Validation accuracy: 0.8952\n",
      "Epoch 120: progress time is 34281.0 sec\n",
      "Validation loss: 0.3831, Validation accuracy: 0.9072\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:0'), tensor(2156., device='cuda:0'))\n",
      "Epoch 130: progress time is 37013.42 sec\n",
      "Validation loss: 0.5825, Validation accuracy: 0.8616\n",
      "Epoch 140: progress time is 39739.99 sec\n",
      "Validation loss: 0.5214, Validation accuracy: 0.8712\n",
      "Epoch 150: progress time is 42465.83 sec\n",
      "Validation loss: 0.5434, Validation accuracy: 0.8600\n",
      "Epoch 160: progress time is 45192.21 sec\n",
      "Validation loss: 0.5563, Validation accuracy: 0.8620\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:0'), tensor(1792., device='cuda:0'))\n",
      "Epoch 170: progress time is 47915.39 sec\n",
      "Validation loss: 0.8230, Validation accuracy: 0.7980\n",
      "Epoch 180: progress time is 50640.46 sec\n",
      "Validation loss: 0.9332, Validation accuracy: 0.7828\n",
      "Epoch 190: progress time is 53365.99 sec\n",
      "Validation loss: 0.7872, Validation accuracy: 0.8064\n",
      "Epoch 200: progress time is 56087.68 sec\n",
      "Validation loss: 0.7488, Validation accuracy: 0.8204\n",
      "==> Optimization finished! Best validation accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##cifar100 \n",
    "##scheduler 실행 : multistepLR , lr 0.1*0.2*0.2\n",
    "fine_tuning(model, mode = mode, EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 node의 갯수 : (tensor(4480., device='cuda:2'), tensor(4480., device='cuda:2'))\n",
      "==> Training starts!\n",
      "1번 자르고 fine tuning을 시작합니다.\n",
      "1번 pruning 이후 남은 node 는 : (tensor(3736., device='cuda:2'), tensor(3736., device='cuda:2'))\n",
      "Epoch 10: progress time is 2739.25 sec\n",
      "Validation loss: 0.6960, Validation accuracy: 0.8056\n",
      "Epoch 20: progress time is 5470.1 sec\n",
      "Validation loss: 0.7759, Validation accuracy: 0.7916\n",
      "Epoch 30: progress time is 8200.82 sec\n",
      "Validation loss: 0.9642, Validation accuracy: 0.7568\n",
      "Epoch 40: progress time is 10937.89 sec\n",
      "Validation loss: 0.8706, Validation accuracy: 0.7684\n",
      "2번 자르고 fine tuning을 시작합니다.\n",
      "2번 pruning 이후 남은 node 는 : (tensor(3112., device='cuda:2'), tensor(3112., device='cuda:2'))\n",
      "Epoch 50: progress time is 13649.64 sec\n",
      "Validation loss: 1.0774, Validation accuracy: 0.7200\n",
      "Epoch 60: progress time is 16352.32 sec\n",
      "Validation loss: 1.0680, Validation accuracy: 0.7248\n",
      "Epoch 70: progress time is 19061.2 sec\n",
      "Validation loss: 0.6628, Validation accuracy: 0.8324\n",
      "Epoch 80: progress time is 21765.04 sec\n",
      "Validation loss: 0.6490, Validation accuracy: 0.8324\n",
      "3번 자르고 fine tuning을 시작합니다.\n",
      "3번 pruning 이후 남은 node 는 : (tensor(2592., device='cuda:2'), tensor(2592., device='cuda:2'))\n",
      "Epoch 90: progress time is 24470.85 sec\n",
      "Validation loss: 0.7722, Validation accuracy: 0.7952\n",
      "Epoch 100: progress time is 27176.96 sec\n",
      "Validation loss: 0.7602, Validation accuracy: 0.8076\n",
      "Epoch 110: progress time is 29884.34 sec\n",
      "Validation loss: 0.7785, Validation accuracy: 0.8068\n",
      "Epoch 120: progress time is 32589.97 sec\n",
      "Validation loss: 0.7936, Validation accuracy: 0.8088\n",
      "4번 자르고 fine tuning을 시작합니다.\n",
      "4번 pruning 이후 남은 node 는 : (tensor(2156., device='cuda:2'), tensor(2156., device='cuda:2'))\n",
      "Epoch 130: progress time is 35300.77 sec\n",
      "Validation loss: 0.8772, Validation accuracy: 0.7868\n",
      "Epoch 140: progress time is 38010.6 sec\n",
      "Validation loss: 0.8515, Validation accuracy: 0.7976\n",
      "Epoch 150: progress time is 40720.66 sec\n",
      "Validation loss: 0.8198, Validation accuracy: 0.8040\n",
      "Epoch 160: progress time is 43429.13 sec\n",
      "Validation loss: 0.8539, Validation accuracy: 0.7956\n",
      "5번 자르고 fine tuning을 시작합니다.\n",
      "5번 pruning 이후 남은 node 는 : (tensor(1792., device='cuda:2'), tensor(1792., device='cuda:2'))\n",
      "Epoch 170: progress time is 46141.43 sec\n",
      "Validation loss: 0.9956, Validation accuracy: 0.7532\n",
      "Epoch 180: progress time is 48852.99 sec\n",
      "Validation loss: 1.0778, Validation accuracy: 0.7500\n",
      "Epoch 190: progress time is 51566.24 sec\n",
      "Validation loss: 1.0147, Validation accuracy: 0.7612\n",
      "Epoch 200: progress time is 54277.23 sec\n",
      "Validation loss: 0.9852, Validation accuracy: 0.7660\n",
      "==> Optimization finished! Best validation accuracy: 0.8324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (M_relu): M_relu()\n",
       "  (layer1): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): M_BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): M_BasicBlock(\n",
       "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu1): M_relu()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (M_relu2): M_relu()\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=640, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##cifar100 \n",
    "##scheduler 실행 : multistepLR , lr 0.1*0.2\n",
    "fine_tuning(model, mode = mode, EPOCHS = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9563; Test accuracy: 0.9563\n"
     ]
    }
   ],
   "source": [
    "## cifar10\n",
    "check_prune = torch.load(\"./saved_tuning/28x10_CIFAR10_scheduler_cosine_lr0.1*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "send_email('28x2_CIFAR10_scheduler_cosine finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9582; Test accuracy: 0.9582\n"
     ]
    }
   ],
   "source": [
    "## cifar10\n",
    "check_prune = torch.load(\"./saved_tuning/28x10_0.6_CIFAR10_scheduler_mult_lr0.1*0.2*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "send_email('28x2_CIFAR10_scheduler_cosine finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 7906; Test accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./saved_tuning_CIFAR100/28x10_0.6_multstepLR_lr0.1*0.2*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "send_email('28x10_0.6_multstepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 7883; Test accuracy: 0.7883\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./saved_tuning_CIFAR100/28x10_0.6_multstepLR_lr0.1*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x10_0.6_multstepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seed 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9554; Test accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "## cifar10\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR10/28x10_0.6_multistepLR_lr0.1*0.2*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x2_multistepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9570; Test accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR10/28x10_0.6_cosine_lr0.1*0.2*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x2_multistepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR10/28x10_0.6_multistepLR_lr0.1*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x2_multistepLR_lr0.1*0.2*0.2 finished')b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9554; Test accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR10/28x10_0.6_multistepLR_lr0.1*0.2*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x10_0.6_multistepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9568; Test accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR10/28x10_0.6_multistepLR_lr0.1*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x10_0.6_multistepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 7866; Test accuracy: 0.7866\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR100/28x10_0.6_multistepLR_lr0.1*0.2*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x10_0.6_multistepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 7851; Test accuracy: 0.7851\n"
     ]
    }
   ],
   "source": [
    "## cifar100\n",
    "check_prune = torch.load(\"./save_seed10_CIFAR100/28x10_0.6_multistepLR_lr0.1*0.2.pth\")\n",
    "\n",
    "model.load_state_dict(check_prune['state_dict'])\n",
    "\n",
    "test_model(model)\n",
    "\n",
    "# send_email('28x10_0.6_multistepLR_lr0.1*0.2*0.2 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
